{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,configuration):\n",
    "        tf.reset_default_graph()\n",
    "        self.configuration = configuration\n",
    "        self.X = tf.placeholder(shape=[None, self.configuration[\"contextSize\"]-1],dtype=tf.int32)\n",
    "        self.Y = tf.placeholder(shape=[None, self.configuration[\"contextSize\"]-1],dtype=tf.int32)\n",
    "        self.res_block = configuration[\"res_block\"]\n",
    "        self.train()\n",
    "\n",
    "    def ConvolutionLayer(self,x, filter_shape):\n",
    "        #with tf.variable_scope(\"layer_%d\"%i):\n",
    "        Wl = tf.Variable(tf.random_normal(filter_shape, stddev=1),name=\"linear_W\")\n",
    "        bl = tf.Variable(tf.constant(0.1, shape=[filter_shape[-1]]), name=\"linear_b\")\n",
    "        conv_w = tf.nn.bias_add(tf.nn.conv2d(x, Wl,strides=[1, 1, 1, 1],padding=\"SAME\"),bl)\n",
    "        \n",
    "        Wv = tf.Variable(tf.truncated_normal(shape=filter_shape),name=\"gated_W\")\n",
    "        bv = tf.Variable(tf.constant(0.1, shape=[filter_shape[-1]]), name=\"gated_b\")\n",
    "        conv_v = tf.nn.bias_add(tf.nn.conv2d(x, Wv,strides=[1, 1, 1, 1],padding=\"SAME\"),bv)\n",
    "        \n",
    "        h = conv_w * tf.nn.sigmoid(conv_v)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def train(self):\n",
    "        embeddingLayer = self.EmbeddingLayer()\n",
    "        h = embeddingLayer\n",
    "        res_input = h\n",
    "        for i in xrange(self.configuration[\"numLayers\"]):\n",
    "            depth = h.get_shape()[-1]\n",
    "            num_filter = self.configuration[\"filterSize\"] if i<self.configuration[\"numLayers\"]-1 else 1\n",
    "            shape = [self.configuration[\"filterH\"], self.configuration[\"embeddingSize\"], int(depth), num_filter]\n",
    "            with tf.variable_scope(\"layer_%d\"%i):\n",
    "                h = self.ConvolutionLayer(h, shape)\n",
    "                if i%self.res_block == 0:\n",
    "                    h += res_input\n",
    "                    res_input = h\n",
    "\n",
    "        h = tf.reshape(h, (-1, self.configuration[\"embeddingSize\"]))\n",
    "        print h.get_shape()\n",
    "        y_shape = self.Y.get_shape().as_list()\n",
    "        y_shape[0] = self.configuration[\"batchSize\"]\n",
    "        self.Y = tf.reshape(self.Y, (y_shape[0] * y_shape[1], 1))\n",
    "        print self.Y.get_shape()\n",
    "        softmax_w = tf.Variable(tf.random_normal([self.configuration[\"vocabSize\"], self.configuration[\"embeddingSize\"]], stddev=0.5), name=\"output_weights\")\n",
    "        print softmax_w.get_shape()\n",
    "        softmax_b = tf.Variable(tf.random_normal([self.configuration[\"vocabSize\"]], stddev=0.5), name=\"output_weights\")\n",
    "        self.Y = tf.cast(self.Y,tf.float32)\n",
    "        self.loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(softmax_w, softmax_b, self.Y,h, self.configuration[\"numSampled\"], self.configuration[\"vocabSize\"]))\n",
    "\n",
    "        trainer = tf.train.MomentumOptimizer(self.configuration[\"learningRate\"], self.configuration[\"momentum\"])\n",
    "        gradients = trainer.compute_gradients(self.loss)\n",
    "        clipped_gradients = [(tf.clip_by_value(_[0], -self.configuration[\"gradClip\"], self.configuration[\"gradClip\"]), _[1]) for _ in gradients]\n",
    "        self.optimizer = trainer.apply_gradients(clipped_gradients)\n",
    "        self.perplexity = tf.exp(self.loss)\n",
    "        print \"Here\"\n",
    "        self.create_summaries()    \n",
    "        \n",
    "    def create_summaries(self):\n",
    "        tf.summary.scalar(\"loss\", self.loss)\n",
    "        tf.summary.scalar(\"perplexity\", self.perplexity)\n",
    "        self.merged_summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    def EmbeddingLayer(self):\n",
    "        embeddings = tf.Variable(tf.random_normal([self.configuration[\"vocabSize\"], self.configuration[\"embeddingSize\"]], stddev=.01), name=\"embeddings\")\n",
    "        embed = tf.nn.embedding_lookup(embeddings, self.X)\n",
    "        return tf.expand_dims(embed, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y, vocab_maping = get_data()\n",
    "\n",
    "# vocab_size = len(vocab_maping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.sampled_softmax_loss()\n",
    "# tf.nn.nce_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\"vocabSize\":200,\n",
    "                \"embeddingSize\":200,\n",
    "                 \"filterSize\":64, \n",
    "                 \"numLayers\": 10, \n",
    "                 \"blockSize\":5, \n",
    "                 \"filterH\":5, \n",
    "                 \"contextSize\":20, \n",
    "                 \"batchSize\":20, \n",
    "                 \"epochs\":50, \n",
    "                 \"numSampled\":1, \n",
    "                 \"learningRate\": 0.1, \n",
    "                 \"momentum\": 0.99, \n",
    "                 \"gradClip\": 0.1, \n",
    "                 \"numBatches\": 0, \n",
    "                 \"directory\":\"./Data/\",\n",
    "                 \"filterW\": 200,\n",
    "                 \"res_block\": 2,\n",
    "                 \"summaryPath\": \"./\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200)\n",
      "(420, 1)\n",
      "(200, 200)\n",
      "Here\n",
      "Started Model Training...\n",
      "AB Here\n",
      "Is k baad\n",
      "Epoch: 0.00,  Loss: 35810790251455053824.00\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Model instance has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-95a42bff3f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mperp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Perplexity: %.2f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mperp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Model instance has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "configuration[\"contextSize\"] += configuration[\"filterH\"]/2\n",
    "x_batches, y_batches = du.prepare_data(configuration)\n",
    "model = Model(configuration)\n",
    "\n",
    "print \"Started Model Training...\"\n",
    "\n",
    "batch_idx = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary_writer = tf.summary.FileWriter(configuration[\"summaryPath\"], graph=sess.graph)\n",
    "    for i in xrange(configuration[\"epochs\"]):\n",
    "        for j in xrange(configuration[\"numBatches\"]):\n",
    "            inputs, labels, batch_idx = du.get_batch(x_batches, y_batches, batch_idx)\n",
    "            print \"AB Here\"\n",
    "            _, l = sess.run([model.optimizer, model.loss], feed_dict={model.X:inputs, model.Y:labels})\n",
    "            print \"Is k baad\"\n",
    "        print \"Epoch: %.2f,  Loss: %.2f\"%(i, l)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            perp = sess.run(model.perplexity, feed_dict={model.X:inputs, model.Y:labels})\n",
    "            print \"Perplexity: %.2f\"%perp\n",
    "        summaries = sess.run(model.merged_summary_op, feed_dict={model.X:inputs, model.Y:labels})\n",
    "        summary_writer.add_summary(summaries, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
